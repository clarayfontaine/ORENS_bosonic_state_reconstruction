{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING W-FUNCTION POINTS\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import h5py\n",
    "from qutip import *\n",
    "from estimation import *\n",
    "from data_processing import *\n",
    "from scipy.io import savemat\n",
    "from targets import *\n",
    "import exp_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check yourself: print function, dimension, and number of displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n",
      "D=6\n",
      "nD=35\n"
     ]
    }
   ],
   "source": [
    "print(f\"{exp_params.which_function}\\nD={exp_params.D}\\nnD={exp_params.nD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fock0' 'fock01' 'fock0i1' 'fock02' 'fock0i2' 'fock1' 'fock03' 'fock0i3'\n",
      " 'fock12' 'fock1i2' 'fock04' 'fock0i4' 'fock13' 'fock1i3' 'fock2' 'fock05'\n",
      " 'fock0i5' 'fock14' 'fock1i4' 'fock23' 'fock2i3' 'fock15' 'fock1i5'\n",
      " 'fock24' 'fock2i4' 'fock3' 'fock25' 'fock2i5' 'fock34' 'fock3i4' 'fock35'\n",
      " 'fock3i5' 'fock4' 'fock45' 'fock4i5' 'fock5']\n"
     ]
    }
   ],
   "source": [
    "state_list = exp_params.fock_state_list\n",
    "print(state_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data_directory = r\"data\\fidelity_v_dimension\\W\\D\" + str(exp_params.D)\n",
    "all_files = np.array(os.listdir(exp_data_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory for target states generated from grape (we don't use ideal when we're processing experimental data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPE generated target states\n",
    "target_states = r\"target_states\" # path to directory of target states generated from grape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather linear inversion variables used to generate Least-Squares estimator, $\\rho_{LS}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map_variables = np.load(\n",
    "    f\"map_variables\\map_variables_D={exp_params.D}_nD={exp_params.nD}_W.npz\"\n",
    ")\n",
    "\n",
    "\n",
    "W = map_variables[\"W\"]\n",
    "\n",
    "beta = map_variables[\"beta\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through the states. For each state: 1) collect the observable outcomes, 2) perform linear inversion with the map to get $\\rho_{LS}$, 3) perform both MLE and Bayesian, and 4) record in numpy arrays the fidelities, standard deviations, and $\\rho_{BME}$ for each. This saves both the normal Wigner and corrected Wigner information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_MLE_corr = np.zeros(len(state_list), dtype=float)\n",
    "F_MLE_norm = np.zeros(len(state_list), dtype=float)\n",
    "\n",
    "\n",
    "F_Bayes_BME_corr = np.zeros(len(state_list), dtype=float)\n",
    "F_Bayes_BME_norm = np.zeros(len(state_list), dtype=float)\n",
    "final_rho_BME_corr = np.zeros(\n",
    "    (len(state_list), exp_params.D, exp_params.D), dtype=\"complex_\"\n",
    ")\n",
    "final_rho_BME_norm = np.zeros(\n",
    "    (len(state_list), exp_params.D, exp_params.D), dtype=\"complex_\"\n",
    ")\n",
    "final_rho_MLE_corr = np.zeros(\n",
    "    (len(state_list), exp_params.D, exp_params.D), dtype=\"complex_\"\n",
    ")\n",
    "final_rho_MLE_norm = np.zeros(\n",
    "    (len(state_list), exp_params.D, exp_params.D), dtype=\"complex_\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clara\\AppData\\Local\\Temp\\ipykernel_7336\\1733429237.py:35: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  data_corr[point - 1] = aux - aux_m\n",
      "C:\\Users\\clara\\AppData\\Local\\Temp\\ipykernel_7336\\1733429237.py:36: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  data_norm[point - 1] = 2 * aux - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 0: fock0, corr: 0.9029379896178136\n",
      "state 0: fock0, norm: 0.8368058097286523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j, state_name in enumerate(state_list):  # State List\n",
    "    data_corr = np.zeros([exp_params.nD])  # Initialize data vector\n",
    "    data_norm = np.zeros([exp_params.nD])  # Initialize data vector\n",
    "\n",
    "    for point in range(1, exp_params.nD + 1):  # Point1 to Point35\n",
    "\n",
    "        ending = (\n",
    "            \"_grape_\"\n",
    "            + str(state_name)\n",
    "            + \"_point\"\n",
    "            + str(point)\n",
    "            + \".h5\"\n",
    "        )\n",
    "        matching = [\n",
    "            filename for filename in all_files if filename.endswith(str(ending))\n",
    "        ]\n",
    "\n",
    "        filepath = exp_data_directory + \"/\" + matching[0]\n",
    "        file = h5py.File(filepath, \"r\")\n",
    "        # selected_data, selected_data_m = select2_flat(filepath, postSel)\n",
    "        signal, signal_m = post_selection_W(filepath)\n",
    "        # signal_m = np.average(selected_data_m)\n",
    "\n",
    "        if state_name in exp_params.pes_after_grape[:, 0]:\n",
    "            pge = exp_params.pes_after_grape[\n",
    "                (exp_params.pes_after_grape[:, 0] == state_name), 1\n",
    "            ].astype(float)\n",
    "\n",
    "        else:\n",
    "            pge = exp_params.pe_after_grape_avg\n",
    "\n",
    "        aux = (signal - pge) / (1 - 2 * pge)\n",
    "        aux_m = (signal_m - pge) / (1 - 2 * pge)\n",
    "\n",
    "        data_corr[point - 1] = aux - aux_m\n",
    "        data_norm[point - 1] = 2 * aux - 1\n",
    "\n",
    "    rho_est_corr, qRho_est_corr = get_LS_and_MLE_rho_est(\n",
    "        data_corr, W, beta, exp_params.D, exp_params.nD\n",
    "    )\n",
    "    rho_est_norm, qRho_est_norm = get_LS_and_MLE_rho_est(\n",
    "        data_norm, W, beta, exp_params.D, exp_params.nD\n",
    "    )\n",
    "\n",
    "    rho_tar_qc = Y_target(state_name, target_states, qdim=3, cdim=30)\n",
    "\n",
    "    rho_tar_c = Qobj(rho_tar_qc.ptrace(1)[0 : exp_params.D, 0 : exp_params.D])\n",
    "    rho_tar_c = rho_tar_c / rho_tar_c.tr()  # normalise it, .unit()\n",
    "\n",
    "    Fmean_bayes_corr, Fstd_bayes_corr, rho_BME_corr = bayesian_rho_est(\n",
    "        numSamp=2**10,\n",
    "        N=exp_params.N_exp,\n",
    "        rho_tar=rho_tar_c,\n",
    "        rhoLS=rho_est_corr.full(),\n",
    "    )\n",
    "    Fmean_bayes_norm, Fstd_bayes_norm, rho_BME_norm = bayesian_rho_est(\n",
    "        numSamp=2**10,\n",
    "        N=exp_params.N_exp,\n",
    "        rho_tar=rho_tar_c,\n",
    "        rhoLS=rho_est_norm.full(),\n",
    "    )\n",
    "    F_Bayes_BME_corr[j] = fidelity(rho_tar_c, Qobj(rho_BME_corr)) ** 2\n",
    "    F_Bayes_BME_norm[j] = fidelity(rho_tar_c, Qobj(rho_BME_norm)) ** 2\n",
    "\n",
    "    F_MLE_corr[j] = fidelity(rho_tar_c, qRho_est_corr) ** 2\n",
    "    F_MLE_norm[j] = fidelity(rho_tar_c, qRho_est_norm) ** 2\n",
    "\n",
    "    final_rho_BME_corr[j, :, :] = rho_BME_corr\n",
    "    final_rho_BME_norm[j, :, :] = rho_BME_norm\n",
    "\n",
    "    final_rho_MLE_corr[j, :, :] = qRho_est_corr\n",
    "    final_rho_MLE_norm[j, :, :] = qRho_est_norm\n",
    "\n",
    "    print(f\"state {j}: {state_name}, corr: {F_Bayes_BME_corr[j]}\")\n",
    "    print(f\"state {j}: {state_name}, norm: {F_Bayes_BME_norm[j]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results in an npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\n",
    "    f\"results_dimensions\\exp\\W\\Bayes_F_D={exp_params.D}_nD={exp_params.nD}_BME_MLE_rho_corr_norm_W.npz\",\n",
    "    F_Bayes_BME_corr=F_Bayes_BME_corr,\n",
    "    F_Bayes_BME_norm=F_Bayes_BME_norm,\n",
    "    F_MLE_corr=F_MLE_corr,\n",
    "    F_MLE_norm=F_MLE_norm,\n",
    "    final_rho_BME_corr=final_rho_BME_corr,\n",
    "    final_rho_BME_norm=final_rho_BME_norm,\n",
    "    final_rho_MLE_corr=final_rho_MLE_corr,\n",
    "    final_rho_MLE_norm=final_rho_MLE_norm,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
